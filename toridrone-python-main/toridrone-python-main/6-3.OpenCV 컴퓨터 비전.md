# 이미지에서 원하는 부분을 찾아서 표시하기
* 깃허브에서 'whole.png'와 'part.png'를 다운로드 받아서 파이썬 파일과 같은 경로에 놓습니다.
* 깃허브주소 : https://github.com/jerrytohub/toridrone-python/tree/main/image
* 토리드론과 조종기가 함께 들어있는 이미지입니다. 
* 전체 이미지 파일 이름은 'whole.png'입니다.
* 토리드론 이미지 파일 이름은 'part.png'입니다.
* 전체 이미지에서 토리드론을 찾아서 사각형으로 표시해보겠습니다.
* 이미지에서 원하는 것을 인식하기 위해서 사진을 Gray 스케일로 바꿉니다.
* Gray 스케일 처리를 하면 더욱 사물의 경계나 모양이 뚜렷하게 나올 수 있어 더 쉽게 인식할 수 있습니다.
* cv2.cvtColor(이미지객체, cv2.COLOR_BGR2GRAY)로 Gray 스케일로 바꿉니다.
* cv.imread(경로, 0)로 사진을 Gray 스케일로 읽을 수 있습니다.
* cv2.matchTemplate(대상, 찾으려는 것, 방식)으로 일치하는 영역을 찾습니다.
* return되는 값은 Gray 이미지로, 원본의 픽셀이 템플릿 이미지와 유사한 정도를 표현합니다.
* 원본 이미지에 템플릿 이미지를 왼쪽 위부터 오른쪽으로 이동하면서 계속 비교합니다.
* cv2.TM_SQDIFF는 전체에서 원하는 부분을 찾는 알고리즘입니다. 다양한 알고리즘으로 찾을 수 있습니다.
  * cv2.TM_SQDIFF
  * cv2.TM_SQDIFF_NORMED
  * cv2.TM_CCORR
  * cv2.TM_CCORR_NORMED
* cv2.minMaxLoc(result)는 찾은 영역의 최소 포인터, 최대 포인터, 최소 지점, 최대 지점을 반환합니다.
```python
import cv2

whole = cv2.imread('whole.png', 0) # 전체 이미지를 Gray 스케일로 읽습니다.
part = cv2.imread('part.png',0) # 부분 이미지를 Gray 스케일로 읽습니다.
origin = cv2.imread('whole.png') # 전체 이미지를 Color로 읽습니다.
result = cv2.matchTemplate(whole, part, cv2.TM_SQDIFF) # 전체 이미지에서 부분 이미지를 찾습니다.
minVal, maxVal, minLoc, maxLoc = cv2.minMaxLoc(result)
x, y = minLoc # 찾은 영역의 좌푯값을 확인합니다.
h, w = part.shape # 이미지를 Gray 스케일로 읽으면 세로와 가로 크기만 알 수 있습니다.
origin = cv2.rectangle(origin, (x, y), (x + w, y + h), (0,0,255), 2) #x, y에 부분 이미지의 가로와 세로 크기를 더해서 좌표를 정합니다.
cv2.imshow('search', origin)
cv2.waitKey(0)
cv2.destroyAllWindows()
```

# OpenCV로 영상을 처리하기
* 컴퓨터에 카메라를 연결하고 촬영한 것을 화면에 나타내보겠습니다.
* VideoCapture 객체를 만들어서 동영상을 읽습니다.
* VideoCapture 객체를 만들 때 숫자를 입력합니다. 번호는 컴퓨터에 연결된 장치번호입니다. 0부터 입력해봅니다.
* isOpened()로 동영상 파일을 열렸는지, 동영상을 잘 촬영하고 있는지 확인합니다.
* read()로 읽으면 2가지 값을 반환합니다. 첫번째는 성공여부입니다. 성공하면 True, 그렇지 않으면 False입니다. 두번째는 읽은 프레임입니다. 이 프레임을 imshow를 사용해서 화면에 나타내면 됩니다.
* 카메라가 열리는데 시간이 좀 걸릴 수 있습니다.
```python
import cv2

capture = cv2.VideoCapture(0) # VideoCapture 객체를 만듭니다.

while capture.isOpened(): # 동영상을 잘 촬영하고 있다면
    # ret : 성공여부 / frame : 프레임
    ret, frame = capture.read() 
    if not ret: # 성공하지 않았다면
        continue
    # frame을 화면에 보여줍니다.
    cv2.imshow('VideoFrame', frame) 
   
    # 0.001초 기다립니다. 기다리는 시간이 없으면 프로그램이 종료될 수 있습니다.
    # 누른 키를 변수에 저장할 수 있습니다.
    # 키마다 고유의 숫자값이 있습니다.
    key = cv2.waitKey(1) 
    
    # 27번은 <Esc> 키입니다. <Esc> 키를 누르면 while 문이 종료됩니다.
    if key == 27:
        break
    
capture.release()
cv2.destroyAllWindows()
```
* 좌우가 바뀐 상태로 영상이 나옵니다. cv2.flip(frame, 1)으로 좌우 반전을 합니다.
* 인공지능이  영상을 처리할 때 Gray 스케일로 바꿔야 하는 경우가 있기 때문에 Gray 스케일로 바꾸는 방법도 알아보겠습니다.
* cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)로 Gray 스케일로 바꿉니다.
```python
import cv2

capture = cv2.VideoCapture(0)

while capture.isOpened():
    ret, frame = capture.read() 
    if not ret: 
        continue
    frame = cv2.flip(frame, 1) # 좌우 반전합니다.
    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) # gray 스케일로 바꿉니다.
    cv2.imshow('VideoFrame', grayframe) # grayframe을 화면에 보여줍니다.
    key = cv2.waitKey(1) 
    if key == 27:
        break
    
capture.release()
cv2.destroyAllWindows()
```

# 눈 인식 프로그램 만들기
* Haarcascade를 사용해서 눈을 인식하는 프로그램을 만들어 보겠습니다.
* Haarcascade는 컴퓨터 비전 분야에서 얼굴 인식, 눈 인식, 자동차 번호판 인식 등 다양한 물체(객체)을 인식하는 데 사용되는 알고리즘입니다. OpenCV 라이브러리에서 Haarcascade를 사용할 수 있습니다. 
* https://github.com/opencv/opencv/tree/master/data/haarcascades 에서 데이터를 다운로드 받아서 사용합니다.
* haarcascade_eye.xml를 선택합니다. 
* 다운로드 버튼을 클릭해서 파이썬 파일 경로에 다운로드합니다.
* CascadeClassifier(캐스케이드 분류기)로 원하는 물체(객체)를 인식합니다. CascadeClassifier에 입력한 데이터로 영상을 분석해서 찾아줍니다.
* 영상을 찍고 좌우 반전을 합니다. 그리고 Gray 스케일로 바꿉니다.
* 영상을 더 잘 분석할 수 있도록 평활화(equalizeHist)를 합니다. equalizeHist는 히스토그램 평활화입니다. 밝기 값이 몰려 있어서 어둡기만한 영상 또는 밝기만 한 영상을 좀 더 선명한 영상으로 만듭니다.
* 그리고 detectMultiScale로 영상을 분석합니다.
```python
import cv2

capture = cv2.VideoCapture(0)

# 분류기 객체를 만듭니다.
cascade = cv2.CascadeClassifier() 

# 데이터를 입력합니다.
cascade.load('haarcascade_eye.xml') 

while capture.isOpened():
    ret, frame = capture.read()
    if not ret: 
        continue
    frame = cv2.flip(frame, 1) 

    # 회색으로 얼굴 인식이 잘 되도록 합니다.
    grayframe = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY) 

    # 영상을 더 잘 분석할 수 있도록 평활화를 합니다.
    grayframe = cv2.equalizeHist(grayframe) 
    
    # Gray 스케일로 바꾼 영상을 분석합니다. 
    # 1.1, 3, 0, (30, 30)는 옵션값입니다.
    objects = cascade.detectMultiScale(grayframe, 1.1, 3, 0, (30, 30))

    # 인식을 하면 x, y, w, h 값을 확인할 수 있습니다.
    # x, y는 인식한 영역의 시작 좌푯값입니다. w와 h는 인식한 영역의 가로와 세로 크기입니다.
    # 눈을 여러 개 인식할 수 있습니다.
    for (x,y,w,h) in objects: 
        # 사각형을 그립니다.         
        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 0, 255), 3)

        # 사각형 위에 'eye'라고 글씨를 씁니다. 
        cv2.putText(frame, 'eye', (x, y-10), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 0, 0))
    cv2.imshow('haarcascade', frame)
    if cv2.waitKey(1) == 27: 
        break
    
capture.release()
cv2.destroyAllWindows()
```
