# 텐서플로우와 티처블 머신
* 텐서플로우(TensorFlow)와 티처블 머신(Teachable Machine)을 사용해서 머신러닝 인공지능 드론을 만들어 보겠습니다. 
  * <엔터> 키를 누르면 머신러닝 인공지능이 영상을 분석합니다.
  * 손바닥을 인식하면 드론이 이륙하고 주먹을 인식하면 드론이 착륙합니다.
* 텐서플로우(TensorFlow)는 구글에서 개발하고 2015년에 오픈 소스로 공개한 머신 러닝 및 딥 러닝 라이브러리입니다.
* 텐서플로우는 다양한 데이터 플로우를 이용해서 복잡한 연산을 수행할 수 있도록 설계된 플랫폼입니다. 주로 신경망 모델을 만들고 학습시킬 때 사용됩니다. 
* 티처블 머신(Teachable Machine)은 구글에서 만든 인공지능 학습 도구입니다.
* 티처블 머신을 사용하면 전문지식이 없이도 웹에서 이미지, 소리 등의 데이터로 기계학습을 시킬 수 있습니다.
* 서로 다른 물체을 구별하는 이미지 분류 모델을 만들거나, 소리를 구별하는 소리 분류 모델을 만들 수 있습니다.
* 티처블 머신을 사용하면 누구나 쉽게 머신 러닝의 기본 개념을 학습하고 적용할 수 있습니다.

# 모델 학습하기
* 티처블 머신을 사용해서 이미지를 학습시키는 방법을 알아보겠습니다. '티처블 머신'이라고 검색합니다.   
![image](https://github.com/user-attachments/assets/8ac3d027-e6ad-41bb-b7c0-d431de983404)
* '시작하기'를 클릭합니다.   
![image](https://github.com/user-attachments/assets/70ff8abd-88f8-4dbf-b3b4-a7fb328b9f42)
* '이미지 프로젝트'를 클릭하고 '표준 이미지 모델'을 선택합니다.   
![image](https://github.com/user-attachments/assets/529dbbfc-9b12-42dd-947b-4d5f8932e0c9)
* ‘Class 1’이라고 이름을 적혀있습니다. 이것을 클래스라고 합니다. 티처블 머신이 사진을 분류할 때 클래스를 기준으로 분류합니다.
* Class 1이라고 적힌 곳을 클릭해서 ‘takeoff’로 바꿉니다. 그리고 웹캠을 클릭합니다.   
![image](https://github.com/user-attachments/assets/58903c0a-c42f-4eff-8277-e9a0e335689a)
* 카메라 사용 관련 메시지가 뜨면 '허용'을 클릭합니다.
* <길게 눌러서 녹화하기>를 클릭해서 손바닥 사진을 찍습니다.
* 30~100개 정도 사진을 찍습니다.
* 너무 많이 찍으면 학습하는데 시간이 오래 걸릴 수 있습니다.
* 다양한 각도에서 사진을 찍습니다.
* 만약 마음에 들지 않는 사진이 있다면 삭제 버튼을 클릭해서 삭제합니다.
* 같은 방법으로 클래스 이름을 ‘landing’으로 정하고 주먹 사진을 찍습니다.
* 이렇게 찍은 사진으로 학습을 시킵니다. <모델 학습시키기>를 클릭합니다.    
![image](https://github.com/user-attachments/assets/7adc670a-8097-4f1c-a7bf-1f6ffdd18457)
* 학습을 할 때 다른 웹페이지를 열거나 브라우저 창을 닫으면 안 됩니다. 학습이 다 될 때까지 기다립니다.
* 학습이 잘 되었는지 확인합니다. 이미지를 학습한 결과에 따라서 사진을 분류합니다. 우리가 정한 클래스 이름으로 이미지를 분류해줍니다.
* 만약 손가락 모양을 잘 구분하지 못하면 다시 학습을 합니다. 
* 이상이 없다면 <모델 내보내기>를 클릭합니다.   
![image](https://github.com/user-attachments/assets/7ea706ba-cab9-4b05-9392-b99bcb0f4b45)
* <Tensorflow>를 선택하고 모델 변환 유형은 <Keras>를 고릅니다. <모델 다운로드>를 클릭합니다.   
![image](https://github.com/user-attachments/assets/fddd31d2-9242-450f-939c-92b537250884)
* 그러면 압축 파일을 다운로드 받을 수 있습니다. 머신러닝 인공지능 드론 프로그램을 만들 때 폴더 경로에 한글이 있으면 다음과 같이 에러가 날 수 있습니다.
  * ```UnicodeDecodeError: 'utf-8' codec can't decode byte 0xa0 in position 7: invalid start byte```
* 압축 파일을 풀면 <keras_model.h5>와 <labels.txt>이 있습니다. 이것을 파이썬 파일 경로로 옮깁니다.
* 'OpenCV Keras'를 클릭하면 OpenCV 예제가 나오는데 여기 있는 코드를 참고합니다.

# 손 모양 분류하기
* OpenCV로 영상을 읽어서 손바닥과 주먹을 잘 구분하는지 확인하겠습니다.
* 텐서플로우(TensorFlow)는 2.12 버전을 설치합니다.
  * ```pip install tensorflow==2.12```
* 텐서플로우를 pip로 설치하면 케라스(keras)와 넘파이(NumPy)가 자동으로 설치됩니다.
* 코드를 실행했는데 설치가 안 되었다는 에러가 생기면 pip로 설치합니다.
 * ```pip install keras```
 * ```pip install numpy```
* 넘파이(NumPy)는 파이썬에서 여러 가지 연산을 위해서 가장 널리 사용되는 라이브러리 중 하나입니다. 데이터 과학, 기계 학습, 공학 등 다양한 분야에서 사용됩니다.
```python
from keras.models import load_model  
import cv2 
import numpy as np

# NumPy에서 배열을 출력할 때 과학적 표기법(scientific notation)을 사용하지 않도록 설정하는 코드입니다. 
# 이를 통해 배열의 요소가 일반적인 소수점 표기법으로 출력됩니다.
np.set_printoptions(suppress=True)

# 모델을 가져옵니다.
model = load_model('keras_model.h5', compile=False)

# labels.txt를 읽습니다.
# 0 takeoff
# 1 landing
class_names = open('labels.txt', 'r', encoding='UTF-8').readlines()

capture = cv2.VideoCapture(0)


while capture.isOpened():    
    ret, frame = capture.read()
    if not ret: 
        continue
    frame = cv2.flip(frame, 1)
     
    # 프레임을 (224, 224) 픽셀 크기로 바꿉니다.
    frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)  
    cv2.imshow('Machine Learning', frame)

    # 프레임을 numpy 배열로 만들고 모델 입력 형태로 바꿉니다.
    frame = np.asarray(frame, dtype=np.float32).reshape(1, 224, 224, 3)

    # 프레임 배열을 정규화홥니다.
    frame = (frame / 127.5) - 1

    # 모델을 예측합니다.
    prediction = model.predict(frame)

    # 가장 높은 예측 값을 가진 클래스 인덱스입니다.
    # 손바닥이면 0, 주먹이면 1이 됩니다.
    index = np.argmax(prediction)
    
    # 클래스 이름을 정합니다.
    # [0 takeoff] 또는 [1 landing]가 됩니다.
    class_name = class_names[index]

    # 해당 클래스의 신뢰도 점수입니다.
    confidence_score = prediction[0][index]
    
    # 클래스 이름을 보여줍니다.
    # 만약 class_name가 '0 takeoff'라면 인덱스가 2부터 문자열을 가져오면 takeoff가 됩니다.
    # 이렇게 인덱스가 2부터 문자열을 가져오면 클래스 이름이 됩니다.
    print('클래스:', class_name[2:], end='')

    # round 함수로 소수 둘째 자리까지 나타냅니다.
    print('신뢰도:', round(confidence_score * 100, 2), '%')
    
    # 너무 빨리 반복되지 않도록 0.5초 기다립니다.
    # 영상이 끊기듯이 촬영됩니다.
    if cv2.waitKey(500) == 27: 
        break

capture.release()
cv2.destroyAllWindows()
```
* 클래스와 신뢰도를 화면에 표시하겠습니다.
```python
# 객체를 복사하기 위해서 copy 모듈을 가져옵니다.
import copy 
from keras.models import load_model  
import cv2 
import numpy as np

np.set_printoptions(suppress=True)
model = load_model('keras_model.h5', compile=False)
class_names = open('labels.txt', 'r', encoding='UTF-8').readlines()
capture = cv2.VideoCapture(0)

while capture.isOpened():    
    ret, frame = capture.read()
    if not ret: 
        continue
    frame = cv2.flip(frame, 1)   
    frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)
    
    # copy 모듈을 사용해서 frame을 복사합니다.    
    origin_frame = copy.deepcopy(frame) 
    frame = np.asarray(frame, dtype=np.float32).reshape(1, 224, 224, 3)
    frame = (frame / 127.5) - 1    
    prediction = model.predict(frame)    
    index = np.argmax(prediction)   
    class_name = class_names[index]
    confidence_score = prediction[0][index]  

    # 클래스 이름을 정합니다.  
    # strip으로 앞 뒤 공백을 지웁니다.
    class_name = class_name[2:].strip()
   
    # 신뢰도를 정합니다.
    confidence_score = round(confidence_score * 100, 2)
    
    # 텍스트를 정합니다.
    text = f'{class_name} : {confidence_score}%'

    # frame에 글자를 쓰고 화면에 보여주면 에러가 생깁니다.
    # origin_frame에 글자를 쓰고 화면에 보여줍니다.
    cv2.putText(origin_frame, text, (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 0, 0))
    cv2.imshow('Machine Learning', origin_frame)
        
    # 영상을 자연스럽게 촬영하도록 기다리는 시간을 1밀리초로 정합니다.
    if cv2.waitKey(1) == 27: 
        break

capture.release()
cv2.destroyAllWindows()
```

# 머신러닝 인공지능 드론 만들기
* 손 모양에 따라서 드론이 이륙/착륙하는 프로그램을 만들어 보겠습니다.
```python
import copy 
from keras.models import load_model  
import cv2 
import numpy as np
from time import sleep
import keyboard
from CodingRider.drone import *
from CodingRider.protocol import *

drone = Drone()
drone.open('COM3')

# is_takeoff 변수로 이륙했는지 확인합니다.
is_takeoff = False

np.set_printoptions(suppress=True)
model = load_model('keras_model.h5', compile=False)
class_names = open('labels.txt', 'r', encoding='UTF-8').readlines()
capture = cv2.VideoCapture(0)

while capture.isOpened():    
    ret, frame = capture.read()
    if not ret: 
        continue
    frame = cv2.flip(frame, 1)   
    frame = cv2.resize(frame, (224, 224), interpolation=cv2.INTER_AREA)      
    origin_frame = copy.deepcopy(frame) 
    frame = np.asarray(frame, dtype=np.float32).reshape(1, 224, 224, 3)
    frame = (frame / 127.5) - 1    
    prediction = model.predict(frame)    
    index = np.argmax(prediction)   
    class_name = class_names[index]
    confidence_score = prediction[0][index] 
    class_name = class_name[2:].strip() 
    confidence_score = round(confidence_score * 100, 2)
    text = f'{class_name} : {confidence_score}%'
    
    # <엔터> 키를 누르면 영상을 분석합니다. 
    if keyboard.is_pressed('enter'):
        # 0번 클래스(takeoff)로 분류했고 이륙하지 않았다면 이륙합니다.
        if (index == 0 and not is_takeoff):
            cv2.putText(origin_frame, text, (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 0, 0))
            cv2.imshow('Machine Learning', origin_frame)
            print('이륙')       
            sleep(2)
            drone.sendTakeOff()
            sleep(5)
            print('이륙 완료')           
            is_takeoff = True
        # 1번 클래스(landing)로 분류했고 이륙했다면 착륙합니다.
        if (index == 1 and is_takeoff):
            cv2.putText(origin_frame, text, (10, 30), cv2.FONT_HERSHEY_DUPLEX, 0.5, (255, 0, 0))
            cv2.imshow('Machine Learning', origin_frame)
            print('착륙')
            drone.sendControlWhile(0, 0, 0, 0, 500) # 제자리에서 0.5초 멈춥니다.
            drone.sendLanding()
            sleep(3)
            print('착륙 완료') 
            is_takeoff = False
    # 안전을 위해서 키보드로 착륙/정지하는 코드도 추가합니다.
    if keyboard.is_pressed('space'):
        print('착륙')
        drone.sendControlWhile(0, 0, 0, 0, 500) 
        drone.sendLanding()
        sleep(3)
        print('착륙 완료')
        is_takeoff = False
    if keyboard.is_pressed('q'):
        print('정지')
        drone.sendControlWhile(0, 0, 0, 0, 500)
        drone.sendStop()
        sleep(3)
        is_takeoff = False
    if cv2.waitKey(1) == 27: 
        break

capture.release()
cv2.destroyAllWindows()
```
